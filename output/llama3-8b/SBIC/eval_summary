*AMBIGUOUS - NOT FIRST*

Number of entries: 4691
Refused answers:0
Missing answers:2
Refusal rate: 0.00042634832658281814
              precision    recall  f1-score   support

         0.0     0.7080    0.7587    0.7325      1981
         1.0     0.8139    0.7712    0.7920      2710

    accuracy                         0.7659      4691
   macro avg     0.7609    0.7650    0.7622      4691
weighted avg     0.7691    0.7659    0.7668      4691

*AMBIGUOUS - SHUFFLED*

Number of entries: 4691
Refused answers:0
Missing answers:2
Refusal rate: 0.00042634832658281814
              precision    recall  f1-score   support

         0.0     0.7141    0.7274    0.7207      1981
         1.0     0.7980    0.7871    0.7925      2710

    accuracy                         0.7619      4691
   macro avg     0.7560    0.7572    0.7566      4691
weighted avg     0.7625    0.7619    0.7622      4691


*DIFFICULT - NOT FIRST*

Number of entries: 4691
Refused answers:0
Missing answers:2
Refusal rate: 0.00042634832658281814
              precision    recall  f1-score   support

         0.0     0.6662    0.7971    0.7258      1981
         1.0     0.8268    0.7081    0.7629      2710

    accuracy                         0.7457      4691
   macro avg     0.7465    0.7526    0.7443      4691
weighted avg     0.7590    0.7457    0.7472      4691


*DIFFICULT - SHUFFLED*

Number of entries: 4691
Refused answers:0
Missing answers:2
Refusal rate: 0.00042634832658281814
              precision    recall  f1-score   support

         0.0     0.7314    0.6310    0.6775      1981
         1.0     0.7549    0.8306    0.7909      2710

    accuracy                         0.7463      4691
   macro avg     0.7431    0.7308    0.7342      4691
weighted avg     0.7450    0.7463    0.7430      4691

*RANDOM - NOT FIRST*

Number of entries: 4691
Refused answers:0
Missing answers:2
Refusal rate: 0.00042634832658281814
              precision    recall  f1-score   support

         0.0     0.7546    0.6567    0.7023      1981
         1.0     0.7708    0.8439    0.8057      2710

    accuracy                         0.7649      4691
   macro avg     0.7627    0.7503    0.7540      4691
weighted avg     0.7640    0.7649    0.7620      4691


*RANDOM - SHUFFLED*

Number of entries: 4691
Refused answers:0
Missing answers:2
Refusal rate: 0.00042634832658281814
              precision    recall  f1-score   support

         0.0     0.7750    0.5982    0.6752      1981
         1.0     0.7483    0.8731    0.8059      2710

    accuracy                         0.7570      4691
   macro avg     0.7616    0.7356    0.7405      4691
weighted avg     0.7596    0.7570    0.7507      4691


- order of labels is relevant: it pushes performances up (different from regular training methods: you always
shuffle the examples to avoid introducing bias)
- selection of examples seems to favor performance - with SBIC ambiguous cases are the best
- Refusal rate limited - due to missing answers
